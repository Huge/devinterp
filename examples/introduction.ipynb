{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Intro to Developmental Interpretability\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/timaeus-research/devinterp/blob/main/examples/introduction.ipynb)\n",
                "\n",
                "Developmental interpretability (\"devinterp\") studies how structure develops over the course of training. \n",
                "\n",
                "## Aim\n",
                "\n",
                "Our aim is to develop tools for detecting, understanding, and preventing dangerous transitions during training — to capabilities, values, behaviors. \n",
                "\n",
                "This library is where we'll put those tools. **It's very much a work in progress** (and we welcome contributions)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set-up"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/home/paperspace/devinterp\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting devinterp\n",
                        "  Using cached devinterp-0.0.3-py3-none-any.whl.metadata (4.5 kB)\n",
                        "Requirement already satisfied: transformers in ./.venv/lib/python3.8/site-packages (4.36.2)\n",
                        "Requirement already satisfied: torchvision in ./.venv/lib/python3.8/site-packages (0.16.2)\n",
                        "Collecting einops==0.6.1 (from devinterp)\n",
                        "  Using cached einops-0.6.1-py3-none-any.whl (42 kB)\n",
                        "Collecting ipykernel==5.5.6 (from devinterp)\n",
                        "  Using cached ipykernel-5.5.6-py3-none-any.whl (121 kB)\n",
                        "Collecting ipywidgets==8.0.7 (from devinterp)\n",
                        "  Using cached ipywidgets-8.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
                        "Collecting jupyter-core==5.3.1 (from devinterp)\n",
                        "  Using cached jupyter_core-5.3.1-py3-none-any.whl.metadata (3.4 kB)\n",
                        "Collecting jupyterlab-widgets==3.0.8 (from devinterp)\n",
                        "  Using cached jupyterlab_widgets-3.0.8-py3-none-any.whl.metadata (4.1 kB)\n",
                        "INFO: pip is looking at multiple versions of devinterp to determine which version is compatible with other requirements. This could take a while.\n",
                        "Collecting devinterp\n",
                        "  Using cached devinterp-0.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
                        "Collecting numpy==1.23.5 (from devinterp)\n",
                        "  Using cached numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
                        "Collecting pandas==1.5.3 (from devinterp)\n",
                        "  Using cached pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
                        "Collecting pydantic==2.1.1 (from devinterp)\n",
                        "  Using cached pydantic-2.1.1-py3-none-any.whl.metadata (136 kB)\n",
                        "Collecting pydantic-core==2.4.0 (from devinterp)\n",
                        "  Using cached pydantic_core-2.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
                        "Collecting torch==2.0.1 (from devinterp)\n",
                        "  Using cached torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
                        "Collecting torchtyping==0.1.4 (from devinterp)\n",
                        "  Using cached torchtyping-0.1.4-py3-none-any.whl (17 kB)\n",
                        "Collecting tqdm==4.65.0 (from devinterp)\n",
                        "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
                        "Collecting ipython-genutils (from ipykernel==5.5.6->devinterp)\n",
                        "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
                        "Requirement already satisfied: ipython>=5.0.0 in ./.venv/lib/python3.8/site-packages (from ipykernel==5.5.6->devinterp) (8.12.3)\n",
                        "Requirement already satisfied: traitlets>=4.1.0 in ./.venv/lib/python3.8/site-packages (from ipykernel==5.5.6->devinterp) (5.14.1)\n",
                        "Requirement already satisfied: jupyter-client in ./.venv/lib/python3.8/site-packages (from ipykernel==5.5.6->devinterp) (8.6.0)\n",
                        "Requirement already satisfied: tornado>=4.2 in ./.venv/lib/python3.8/site-packages (from ipykernel==5.5.6->devinterp) (6.4)\n",
                        "Collecting widgetsnbextension~=4.0.7 (from ipywidgets==8.0.7->devinterp)\n",
                        "  Using cached widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\n",
                        "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.8/site-packages (from jupyter-core==5.3.1->devinterp) (4.1.0)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas==1.5.3->devinterp) (2.8.2)\n",
                        "Collecting pytz>=2020.1 (from pandas==1.5.3->devinterp)\n",
                        "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
                        "Collecting annotated-types>=0.4.0 (from pydantic==2.1.1->devinterp)\n",
                        "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
                        "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.8/site-packages (from pydantic==2.1.1->devinterp) (4.9.0)\n",
                        "Requirement already satisfied: filelock in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->devinterp) (3.13.1)\n",
                        "Requirement already satisfied: sympy in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->devinterp) (1.12)\n",
                        "Requirement already satisfied: networkx in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->devinterp) (3.1)\n",
                        "Requirement already satisfied: jinja2 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->devinterp) (3.1.3)\n",
                        "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->devinterp)\n",
                        "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
                        "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->devinterp)\n",
                        "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
                        "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->devinterp)\n",
                        "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
                        "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->devinterp)\n",
                        "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
                        "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->devinterp)\n",
                        "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
                        "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->devinterp)\n",
                        "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
                        "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->devinterp)\n",
                        "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
                        "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->devinterp)\n",
                        "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
                        "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->devinterp)\n",
                        "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
                        "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->devinterp)\n",
                        "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
                        "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->devinterp)\n",
                        "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
                        "Collecting triton==2.0.0 (from torch==2.0.1->devinterp)\n",
                        "  Using cached triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
                        "Collecting typeguard>=2.11.1 (from torchtyping==0.1.4->devinterp)\n",
                        "  Using cached typeguard-4.1.5-py3-none-any.whl.metadata (3.7 kB)\n",
                        "Collecting setuptools (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->devinterp)\n",
                        "  Using cached setuptools-69.0.3-py3-none-any.whl.metadata (6.3 kB)\n",
                        "Collecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->devinterp)\n",
                        "  Using cached wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
                        "Collecting cmake (from triton==2.0.0->torch==2.0.1->devinterp)\n",
                        "  Using cached cmake-3.28.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
                        "Collecting lit (from triton==2.0.0->torch==2.0.1->devinterp)\n",
                        "  Using cached lit-17.0.6.tar.gz (153 kB)\n",
                        "  Installing build dependencies ... \u001b[?25ldone\n",
                        "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
                        "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
                        "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
                        "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.venv/lib/python3.8/site-packages (from transformers) (0.20.2)\n",
                        "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from transformers) (23.2)\n",
                        "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
                        "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.8/site-packages (from transformers) (2023.12.25)\n",
                        "Requirement already satisfied: requests in ./.venv/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
                        "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.venv/lib/python3.8/site-packages (from transformers) (0.15.0)\n",
                        "Requirement already satisfied: safetensors>=0.3.1 in ./.venv/lib/python3.8/site-packages (from transformers) (0.4.1)\n",
                        "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
                        "Collecting torchvision\n",
                        "  Downloading torchvision-0.16.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
                        "  Downloading torchvision-0.16.0-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
                        "  Downloading torchvision-0.15.2-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.8/site-packages (from torchvision) (10.2.0)\n",
                        "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.8/site-packages (from requests->transformers) (3.6)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests->transformers) (2.1.0)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests->transformers) (2023.11.17)\n",
                        "Requirement already satisfied: backcall in ./.venv/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel==5.5.6->devinterp) (0.2.0)\n",
                        "Requirement already satisfied: decorator in ./.venv/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel==5.5.6->devinterp) (5.1.1)\n",
                        "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel==5.5.6->devinterp) (0.19.1)\n",
                        "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel==5.5.6->devinterp) (0.1.6)\n",
                        "Requirement already satisfied: pickleshare in ./.venv/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel==5.5.6->devinterp) (0.7.5)\n",
                        "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./.venv/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel==5.5.6->devinterp) (3.0.43)\n",
                        "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel==5.5.6->devinterp) (2.17.2)\n",
                        "Requirement already satisfied: stack-data in ./.venv/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel==5.5.6->devinterp) (0.6.3)\n",
                        "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel==5.5.6->devinterp) (4.9.0)\n",
                        "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3->devinterp) (1.16.0)\n",
                        "Requirement already satisfied: importlib-metadata>=3.6 in ./.venv/lib/python3.8/site-packages (from typeguard>=2.11.1->torchtyping==0.1.4->devinterp) (7.0.1)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.8/site-packages (from jinja2->torch==2.0.1->devinterp) (2.1.3)\n",
                        "Requirement already satisfied: pyzmq>=23.0 in ./.venv/lib/python3.8/site-packages (from jupyter-client->ipykernel==5.5.6->devinterp) (25.1.2)\n",
                        "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.8/site-packages (from sympy->torch==2.0.1->devinterp) (1.3.0)\n",
                        "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.8/site-packages (from importlib-metadata>=3.6->typeguard>=2.11.1->torchtyping==0.1.4->devinterp) (3.17.0)\n",
                        "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.8/site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel==5.5.6->devinterp) (0.8.3)\n",
                        "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.8/site-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel==5.5.6->devinterp) (0.7.0)\n",
                        "Requirement already satisfied: wcwidth in ./.venv/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=5.0.0->ipykernel==5.5.6->devinterp) (0.2.13)\n",
                        "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=5.0.0->ipykernel==5.5.6->devinterp) (2.0.1)\n",
                        "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=5.0.0->ipykernel==5.5.6->devinterp) (2.4.1)\n",
                        "Requirement already satisfied: pure-eval in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=5.0.0->ipykernel==5.5.6->devinterp) (0.2.2)\n",
                        "Using cached devinterp-0.0.2-py3-none-any.whl (25 kB)\n",
                        "Using cached ipywidgets-8.0.7-py3-none-any.whl (138 kB)\n",
                        "Using cached jupyter_core-5.3.1-py3-none-any.whl (93 kB)\n",
                        "Using cached jupyterlab_widgets-3.0.8-py3-none-any.whl (214 kB)\n",
                        "Using cached pydantic-2.1.1-py3-none-any.whl (370 kB)\n",
                        "Using cached pydantic_core-2.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
                        "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
                        "Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
                        "Using cached typeguard-4.1.5-py3-none-any.whl (34 kB)\n",
                        "Using cached widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n",
                        "Using cached cmake-3.28.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
                        "Using cached setuptools-69.0.3-py3-none-any.whl (819 kB)\n",
                        "Using cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
                        "Building wheels for collected packages: lit\n",
                        "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
                        "\u001b[?25h  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=f662642324bd2190fa9f0caf73036b430cd95a60eb1846a55262d7869e9b013f\n",
                        "  Stored in directory: /home/paperspace/.cache/pip/wheels/c0/1b/ae/c752907c50ad9673ab23730ee731ce853f2cf69b2d98019dcd\n",
                        "Successfully built lit\n",
                        "Installing collected packages: pytz, lit, ipython-genutils, cmake, widgetsnbextension, wheel, tqdm, setuptools, pydantic-core, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, numpy, jupyterlab-widgets, jupyter-core, einops, annotated-types, typeguard, pydantic, pandas, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, ipykernel, ipywidgets, triton, torch, torchtyping, torchvision, devinterp\n",
                        "  Attempting uninstall: tqdm\n",
                        "    Found existing installation: tqdm 4.66.1\n",
                        "    Uninstalling tqdm-4.66.1:\n",
                        "      Successfully uninstalled tqdm-4.66.1\n",
                        "  Attempting uninstall: numpy\n",
                        "    Found existing installation: numpy 1.24.4\n",
                        "    Uninstalling numpy-1.24.4:\n",
                        "      Successfully uninstalled numpy-1.24.4\n",
                        "  Attempting uninstall: jupyter-core\n",
                        "    Found existing installation: jupyter_core 5.7.1\n",
                        "    Uninstalling jupyter_core-5.7.1:\n",
                        "      Successfully uninstalled jupyter_core-5.7.1\n",
                        "  Attempting uninstall: ipykernel\n",
                        "    Found existing installation: ipykernel 6.29.0\n",
                        "    Uninstalling ipykernel-6.29.0:\n",
                        "      Successfully uninstalled ipykernel-6.29.0\n",
                        "  Attempting uninstall: triton\n",
                        "    Found existing installation: triton 2.1.0\n",
                        "    Uninstalling triton-2.1.0:\n",
                        "      Successfully uninstalled triton-2.1.0\n",
                        "  Attempting uninstall: torch\n",
                        "    Found existing installation: torch 2.1.2\n",
                        "    Uninstalling torch-2.1.2:\n",
                        "      Successfully uninstalled torch-2.1.2\n",
                        "  Attempting uninstall: torchvision\n",
                        "    Found existing installation: torchvision 0.16.2\n",
                        "    Uninstalling torchvision-0.16.2:\n",
                        "      Successfully uninstalled torchvision-0.16.2\n",
                        "Successfully installed annotated-types-0.6.0 cmake-3.28.1 devinterp-0.0.2 einops-0.6.1 ipykernel-5.5.6 ipython-genutils-0.2.0 ipywidgets-8.0.7 jupyter-core-5.3.1 jupyterlab-widgets-3.0.8 lit-17.0.6 numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pandas-1.5.3 pydantic-2.1.1 pydantic-core-2.4.0 pytz-2023.3.post1 setuptools-69.0.3 torch-2.0.1 torchtyping-0.1.4 torchvision-0.15.2 tqdm-4.65.0 triton-2.0.0 typeguard-4.1.5 wheel-0.42.0 widgetsnbextension-4.0.9\n",
                        "Note: you may need to restart the kernel to use updated packages.\n",
                        "Obtaining file:///home/paperspace/devinterp\n",
                        "\u001b[31mERROR: Exception:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
                        "    status = run_func(*args)\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/cli/req_command.py\", line 245, in wrapper\n",
                        "    return func(self, options, args)\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
                        "    requirement_set = resolver.resolve(\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 76, in resolve\n",
                        "    collected = self.factory.collect_root_requirements(root_reqs)\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 534, in collect_root_requirements\n",
                        "    reqs = list(\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 490, in _make_requirements_from_install_req\n",
                        "    cand = self._make_base_candidate_from_link(\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 207, in _make_base_candidate_from_link\n",
                        "    self._editable_candidate_cache[link] = EditableCandidate(\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 318, in __init__\n",
                        "    super().__init__(\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
                        "    self.dist = self._prepare()\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n",
                        "    dist = self._prepare_distribution()\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 328, in _prepare_distribution\n",
                        "    return self._factory.preparer.prepare_editable_requirement(self._ireq)\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\", line 696, in prepare_editable_requirement\n",
                        "    dist = _get_prepared_distribution(\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\", line 71, in _get_prepared_distribution\n",
                        "    abstract_dist.prepare_distribution_metadata(\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/distributions/sdist.py\", line 37, in prepare_distribution_metadata\n",
                        "    self.req.load_pyproject_toml()\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/req/req_install.py\", line 506, in load_pyproject_toml\n",
                        "    pyproject_toml_data = load_pyproject_toml(\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_internal/pyproject.py\", line 64, in load_pyproject_toml\n",
                        "    pp_toml = tomli.loads(f.read())\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_vendor/tomli/_parser.py\", line 102, in loads\n",
                        "    pos = key_value_rule(src, pos, out, header, parse_float)\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_vendor/tomli/_parser.py\", line 326, in key_value_rule\n",
                        "    pos, key, value = parse_key_value_pair(src, pos, parse_float)\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_vendor/tomli/_parser.py\", line 369, in parse_key_value_pair\n",
                        "    pos, value = parse_value(src, pos, parse_float)\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_vendor/tomli/_parser.py\", line 616, in parse_value\n",
                        "    return parse_array(src, pos, parse_float)\n",
                        "  File \"/home/paperspace/devinterp/.venv/lib/python3.8/site-packages/pip/_vendor/tomli/_parser.py\", line 428, in parse_array\n",
                        "    raise suffixed_err(src, pos, \"Unclosed array\")\n",
                        "pip._vendor.tomli.TOMLDecodeError: Unclosed array (at line 25, column 16)\u001b[0m\u001b[31m\n",
                        "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
                        "/home/paperspace/devinterp/examples\n"
                    ]
                }
            ],
            "source": [
                "%pip install devinterp transformers torchvision"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Methods\n",
                "\n",
                "## Local Learning Coefficients\n",
                "\n",
                "The first method we have have online is local learning coefficient estimation ([Lau et al. 2023](https://arxiv.org/abs/2308.12108)). \n",
                "\n",
                "For an in-depth explaination, see [this post](https://www.lesswrong.com/posts/6g8cAftfQufLmFDYT/you-re-counting-your-parameters-wrong). The short version is that: \n",
                "- The (local) learning coefficient $\\hat\\lambda$ is the \"correct\" measure of model complexity. Besides the loss, it's the most principled high-level way to compare models.\n",
                "- We can cheaply estimate the learning coefficient associated to a choice of weights $\\hat w^*$ by using the following formula:\n",
                "\n",
                "$$\n",
                "\\hat\\lambda(\\hat w^*)=\\frac{\\mathbb{E}_{w|\\hat w^*, \\gamma}^{\\beta^*}\\left[n L_n(w)\\right] - n L_n(\\hat w^*)}{\\log n}.\n",
                "$$\n",
                "\n",
                "where, $n$ is the number of (training) samples, $L_n(w)$ is the negative log likelihood (i.e., your objective function), and $\\mathbb{E}_w^{\\beta^*}\\left[n L_n(w)\\right]$ is a \"local average\" of $nL_n(w)$ over a neighborhood of $\\hat w^*$. The parameters $\\gamma$ and $\\beta^*$ control the local averaging.\n",
                "\n",
                "The difficulty is in performing the local average: we need to sample enough points and they need to be both diverse / spread out enough and close enough to the starting weight. To make sure they're spread out enough we use an optimizer like Stochastic Gradient Langevin Dynamics (SGLD), which is SGD plus Gaussian noise.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'devinterp.utils'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "\u001b[1;32m/home/paperspace/devinterp/examples/introduction.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace2/home/paperspace/devinterp/examples/introduction.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdevinterp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mslt\u001b[39;00m \u001b[39mimport\u001b[39;00m estimate_learning_coeff_with_summary\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace2/home/paperspace/devinterp/examples/introduction.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdevinterp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m SGLD\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace2/home/paperspace/devinterp/examples/introduction.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdevinterp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_trace\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpaperspace2/home/paperspace/devinterp/examples/introduction.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m DEVICE \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'devinterp.utils'"
                    ]
                }
            ],
            "source": [
                "import yaml\n",
                "\n",
                "import torch\n",
                "import torchvision\n",
                "from transformers import AutoModelForImageClassification\n",
                "from torch.nn import functional as F\n",
                "\n",
                "from devinterp.slt import estimate_learning_coeff_with_summary\n",
                "from devinterp.optim import SGLD\n",
                "from devinterp.utils import plot_trace\n",
                "\n",
                "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
                        "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
                        "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
                    ]
                }
            ],
            "source": [
                "# Load a pretrained MNIST classifier\n",
                "model = AutoModelForImageClassification.from_pretrained(\"fxmarty/resnet-tiny-mnist\")\n",
                "data = torchvision.datasets.MNIST(\n",
                "    root=\"../data\",\n",
                "    download=True,\n",
                "    transform=torchvision.transforms.Compose(\n",
                "        [\n",
                "            torchvision.transforms.ToTensor(),\n",
                "        ]\n",
                "    ),\n",
                ")\n",
                "loader = torch.utils.data.DataLoader(data, batch_size=256, shuffle=True)\n",
                "\n",
                "\n",
                "def criterion(inputs, outputs):\n",
                "    return F.cross_entropy(inputs.logits, outputs)  # transformers doesn't output a vector\n",
                "\n",
                "\n",
                "learning_coeff_stats = estimate_learning_coeff_with_summary(\n",
                "    model,\n",
                "    loader=loader,\n",
                "    criterion=criterion,\n",
                "    sampling_method=SGLD,\n",
                "    optimizer_kwargs=dict(lr=3e-5, elasticity=1., num_samples=len(data)),\n",
                "    num_chains=3,  # How many independent chains to run\n",
                "    num_draws=200,  # How many samples to draw per chain\n",
                "    num_burnin_steps=0,  # How many samples to discard at the beginning of each chain\n",
                "    num_steps_bw_draws=1,  # How many steps to take between each sample\n",
                "    device=DEVICE,\n",
                ")\n",
                "trace = learning_coeff_stats.pop(\"loss/trace\")\n",
                "\n",
                "print(\"Lambda hat estimates:\")\n",
                "print(yaml.dump(learning_coeff_stats))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Diagnostics\n",
                "\n",
                "Below you'll see what's actually happening when you run `local_learning_coefficients`.\n",
                "\n",
                "We sample 10 different chains, with the same starting positions but different batch schedules and noise realizations at each step. For each of these chains, we take 100 steps using SGLD. We observe the loss at each of these points. At the end, we average the loss across chains, compare it to the initial loss, and apply a correction that depends on the dataset size to get the local learning coefficient. \n",
                "\n",
                "For a healthy chain, the loss should increase rapidly at first and then level off."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
                        "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
                        "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
                    ]
                }
            ],
            "source": [
                "plot_trace(trace, 'L_n(w)', x_axis='Step', title=' Learning Coefficient Trace', plot_mean=False, plot_std=False, fig_size=(12, 9), true_lc = None)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To get a better understanding of the sampling methods, check out [`normal_crossing.ipynb`](../examples/normal_crossing.ipynb) and [`mnist.ipynb`](../examples/mnist.ipynb) where we compare SGLD to a variant known as Stochastic Gradient Nose-Hoover Thermostat (SGNHT), respectively in a simple toy landscape and on MNIST. [`sgld_calibration.ipynb`](../examples/sgld_calibration.ipynb) shows how to gain confidence in using SGLD-based LLC estimation to a model with unknown LLC, and [`diagnostics.ipynb`](../examples/diagnostics.ipynb) shows how to use callbacks to diagnose if your sampling is going well."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Project ideas\n",
                "\n",
                "What can you do with this? We wrote up [a bunch of ideas](https://devinterp.com/projects), most of which are focused on learning coefficient estimation, and we'd recommend starting there. There's a lot of low-hanging fruit. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Other Techniques\n",
                "\n",
                "There are plenty of other techniques that would fit naturally under the umbrella of \"developmental interpretability.\" If you're interested in looking beyond learning coefficient estimation, here are some ideas (we welcome PRs to introduce these methods to the library!):\n",
                "\n",
                "- **Dimensionality reduction techniques**: Run PCA / t-SNE / UMAP / etc. over the weights / [tokens](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html#per-token-loss-intro) / activations over time. For larger models, you'll have to restrict your attention to a subset of the weights and activations for this to be tractable\n",
                "- **Progress measures**. If you have an understanding of some structure at the end of training, you can roll that understanding backwards to track how that structure develops over time. \n",
                "- **Probes**. Similarly, you can train a linear probe from activations onto features, then roll that probe back to previous checkpoints to measure how those features are learned. \n",
                "- **Gradients**. Just look at the gradients! \n",
                "- **Evals**. You can measure performance on a targeted benchmarks to track when the model learns the associated capabilities. \n",
                "- **Covariance estimators**. That's a secret for now. More coming soon!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Systems\n",
                "\n",
                "## Toy Landscapes\n",
                "\n",
                "See [`normal_crossing.ipynb`](../examples/normal_crossing.ipynb) for a demo of how to use the library on a simple toy landscape.\n",
                "\n",
                "## Toy Models of Superposition\n",
                "\n",
                "See [`tms.ipynb`](../examples/tms.ipynb) for a demo of how to use the library on toy models of superposition.\n",
                "\n",
                "## Deep Linear Networks\n",
                "\n",
                "See [`dlns.ipynb`](../examples/dlns.ipynb) for a demo of how to use the library on deep linear networks.\n",
                "\n",
                "## MNIST\n",
                "\n",
                "See [`mnist.ipynb`](../examples/mnist.ipynb) for a demo of how to use the library on MNIST.\n",
                "\n",
                "## ResNets\n",
                "\n",
                "See [`resnets.ipynb`](../examples/resnets.ipynb) for a (basic) demo of how to use the library on ResNets."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
